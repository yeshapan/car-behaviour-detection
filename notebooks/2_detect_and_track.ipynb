{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#project root path\n",
        "PROJECT_ROOT = '/content/drive/My Drive/car-behaviour-project'\n",
        "\n",
        "#key dictionaries defined\n",
        "#input for this notebook:\n",
        "EXTRACTED_FRAMES_INPUT_DIR = os.path.join(PROJECT_ROOT, 'data/extracted_frames')\n",
        "\n",
        "#output for this notebook:\n",
        "TRACKING_OUTPUTS_DIR = os.path.join(PROJECT_ROOT, 'data/tracking_outputs')\n",
        "VISUALIZED_FRAMES_DIR = os.path.join(PROJECT_ROOT, 'data/visualized_tracked_frames') #optional\n",
        "\n",
        "#models directory\n",
        "MODEL_DIR = os.path.join(PROJECT_ROOT, 'models/yolov8')\n",
        "\n",
        "#create directories if they don't exist\n",
        "os.makedirs(EXTRACTED_FRAMES_INPUT_DIR, exist_ok=True) #should exist from Notebook 1\n",
        "os.makedirs(TRACKING_OUTPUTS_DIR, exist_ok=True)\n",
        "os.makedirs(VISUALIZED_FRAMES_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Project Root: {PROJECT_ROOT}\")\n",
        "print(f\"Reading extracted frames from: {EXTRACTED_FRAMES_INPUT_DIR}\")\n",
        "print(f\"Saving tracking data to: {TRACKING_OUTPUTS_DIR}\")\n",
        "print(f\"Saving visualized frames to: {VISUALIZED_FRAMES_DIR}\")\n",
        "print(f\"Models directory: {MODEL_DIR}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8r756s75EyR",
        "outputId": "94792d18-bff3-4e14-c3d1-18674d378052"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Project Root: /content/drive/My Drive/car-behaviour-project\n",
            "Reading extracted frames from: /content/drive/My Drive/car-behaviour-project/data/extracted_frames\n",
            "Saving tracking data to: /content/drive/My Drive/car-behaviour-project/data/tracking_outputs\n",
            "Saving visualized frames to: /content/drive/My Drive/car-behaviour-project/data/visualized_tracked_frames\n",
            "Models directory: /content/drive/My Drive/car-behaviour-project/models/yolov8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ultralytics for YOLO, filterpy for Kalman Filter in SORT, scipy for Hungarian Algorithm in SORT\n",
        "!pip install ultralytics opencv-python numpy filterpy scipy matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cilnPfOXyEzu",
        "outputId": "5be34176-e445-488f-b086-c0c29f27e329"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.146)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: filterpy in /usr/local/lib/python3.11/dist-packages (1.4.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Python implementation of SORT tracker\n",
        "import numpy as np\n",
        "from filterpy.kalman import KalmanFilter\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "def iou_batch(bb_test, bb_gt):\n",
        "    \"\"\"computes Intersection Over Union (IOU) between two sets of bounding boxes.\n",
        "    bb_test:  Nx4 array of N bounding boxes (x1,y1,x2,y2)\n",
        "    bb_gt:    Mx4 array of M bounding boxes (x1,y1,x2,y2)\n",
        "    Returns:  NxM IOU matrix\"\"\"\n",
        "    bb_gt = np.asarray(bb_gt) #ensure bb_gt is a numpy array\n",
        "    bb_test = np.asarray(bb_test) #ensure bb_test is a numpy array\n",
        "\n",
        "    #ensure bb_gt is 2D if it's a single box\n",
        "    if bb_gt.ndim == 1:\n",
        "        bb_gt = bb_gt[np.newaxis, :]\n",
        "    if bb_test.ndim == 1:\n",
        "        bb_test = bb_test[np.newaxis, :]\n",
        "\n",
        "    xx1 = np.maximum(bb_test[:, 0, np.newaxis], bb_gt[:, 0])\n",
        "    yy1 = np.maximum(bb_test[:, 1, np.newaxis], bb_gt[:, 1])\n",
        "    xx2 = np.minimum(bb_test[:, 2, np.newaxis], bb_gt[:, 2])\n",
        "    yy2 = np.minimum(bb_test[:, 3, np.newaxis], bb_gt[:, 3])\n",
        "    w = np.maximum(0., xx2 - xx1)\n",
        "    h = np.maximum(0., yy2 - yy1)\n",
        "    wh = w * h\n",
        "    o = wh / ( (bb_test[:, 2, np.newaxis] - bb_test[:, 0, np.newaxis]) * (bb_test[:, 3, np.newaxis] - bb_test[:, 1, np.newaxis]) + \\\n",
        "               (bb_gt[:, 2] - bb_gt[:, 0]) * (bb_gt[:, 3] - bb_gt[:, 1]) - wh)\n",
        "    return(o)\n",
        "\n",
        "def convert_bbox_to_z(bbox):\n",
        "    \"\"\"takes a bounding box in the form [x1,y1,x2,y2] and returns z in the form [x,y,s,r] where x,y is the centre of the box and s is the scale/area and r is the aspect ratio\"\"\"\n",
        "    w = bbox[2] - bbox[0]\n",
        "    h = bbox[3] - bbox[1]\n",
        "    x = bbox[0] + w/2.\n",
        "    y = bbox[1] + h/2.\n",
        "    s = w * h    #scale is just area\n",
        "    r = w / float(h) if h != 0 else 0 #aspect ratio\n",
        "    return np.array([x, y, s, r]).reshape((4, 1))\n",
        "\n",
        "def convert_x_to_bbox(x, score=None):\n",
        "    \"\"\"takes a bounding box in the centre form [x,y,s,r] and returns it in the form [x1,y1,x2,y2] where x1,y1 is the top-left and x2,y2 is the bottom-right\"\"\"\n",
        "    w = np.sqrt(x[2] * x[3])\n",
        "    h = x[2] / w if w != 0 else 0\n",
        "    if(score==None):\n",
        "        return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.]).reshape((1,4))\n",
        "    else:\n",
        "        return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.,score]).reshape((1,5))\n",
        "\n",
        "class KalmanBoxTracker(object):\n",
        "    \"\"\"this class represents the internal state of individual tracked objects observed as bbox\"\"\"\n",
        "    count = 0\n",
        "    def __init__(self,bbox):\n",
        "        \"\"\"initialises a tracker using initial bounding box\"\"\"\n",
        "        #define constant velocity model\n",
        "        self.kf = KalmanFilter(dim_x=7, dim_z=4)\n",
        "        self.kf.F = np.array([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],[0,0,0,1,0,0,0],  [0,0,0,0,1,0,0],[0,0,0,0,0,1,0],[0,0,0,0,0,0,1]])\n",
        "        self.kf.H = np.array([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],[0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])\n",
        "\n",
        "        self.kf.R[2:,2:] *= 10. #measurement noise covariance matrix\n",
        "        self.kf.P[4:,4:] *= 1000. #give high uncertainty to the unobservable initial velocities\n",
        "        self.kf.P *= 10.\n",
        "        self.kf.Q[-1,-1] *= 0.01 #process noise covariance matrix\n",
        "        self.kf.Q[4:,4:] *= 0.01\n",
        "\n",
        "        self.kf.x[:4] = convert_bbox_to_z(bbox)\n",
        "        self.time_since_update = 0\n",
        "        self.id = KalmanBoxTracker.count\n",
        "        KalmanBoxTracker.count += 1\n",
        "        self.history = []\n",
        "        self.hits = 0\n",
        "        self.hit_streak = 0\n",
        "        self.age = 0\n",
        "\n",
        "    def update(self,bbox):\n",
        "        \"\"\"updates the state vector with observed bbox\"\"\"\n",
        "        self.time_since_update = 0\n",
        "        self.history = []\n",
        "        self.hits += 1\n",
        "        self.hit_streak += 1\n",
        "        self.kf.update(convert_bbox_to_z(bbox))\n",
        "\n",
        "    def predict(self):\n",
        "        \"\"\"advances the state vector and returns the predicted bounding box estimate\"\"\"\n",
        "        if((self.kf.x[6]+self.kf.x[2])<=0): # if s + ds <=0\n",
        "            self.kf.x[6] *= 0.0 # ds = 0\n",
        "        self.kf.predict()\n",
        "        self.age += 1\n",
        "        if(self.time_since_update>0):\n",
        "            self.hit_streak = 0\n",
        "        self.time_since_update += 1\n",
        "        self.history.append(convert_x_to_bbox(self.kf.x))\n",
        "        return self.history[-1]\n",
        "\n",
        "    def get_state(self):\n",
        "        \"\"\"returns the current bounding box estimate\"\"\"\n",
        "        return convert_x_to_bbox(self.kf.x)\n",
        "\n",
        "class Sort(object):\n",
        "    def __init__(self, max_age=1, min_hits=3, iou_threshold=0.3):\n",
        "        \"\"\"sets key parameters for SORT\"\"\"\n",
        "        self.max_age = max_age\n",
        "        self.min_hits = min_hits\n",
        "        self.iou_threshold = iou_threshold\n",
        "        self.trackers = []\n",
        "        self.frame_count = 0\n",
        "        KalmanBoxTracker.count = 0 #reset static counter for multiple Sort instances\n",
        "\n",
        "    def update(self, dets=np.empty((0, 5))):\n",
        "        \"\"\"Params:\n",
        "          dets - a numpy array of detections in the format [[x1,y1,x2,y2,score],[x1,y1,x2,y2,score],...]\n",
        "        Requires: this method must be called once for each frame even with empty detections (use np.empty((0, 5)) for frames without detections).\n",
        "        Returns the a similar array, where the last column is the object ID.\n",
        "        NOTE: The number of objects returned may be different from the number of detections provided\"\"\"\n",
        "        self.frame_count += 1\n",
        "        #get predicted locations from existing trackers.\n",
        "        trks = np.zeros((len(self.trackers), 5))\n",
        "        to_del = []\n",
        "        ret = []\n",
        "        for t, trk in enumerate(trks):\n",
        "            pos = self.trackers[t].predict()[0]\n",
        "            trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]\n",
        "            if np.any(np.isnan(pos)):\n",
        "                to_del.append(t)\n",
        "        trks = np.ma.compress_rows(np.ma.masked_invalid(trks)) #remove invalid (NaN) predictions\n",
        "        for t in reversed(to_del):\n",
        "            self.trackers.pop(t)\n",
        "\n",
        "        #associate detections with existing trackers\n",
        "        if dets.size > 0 and trks.size > 0: #detections and Trackers exist\n",
        "            iou_matrix = iou_batch(dets[:, :4], trks[:, :4])\n",
        "            #hungarian algorithm for assignment\n",
        "            row_ind, col_ind = linear_sum_assignment(-iou_matrix) #we want to maximize IoU, so negate\n",
        "            matched_indices = []\n",
        "            for r, c in zip(row_ind, col_ind):\n",
        "                if iou_matrix[r, c] >= self.iou_threshold:\n",
        "                    matched_indices.append((r,c))\n",
        "\n",
        "            unmatched_detections = [d for d in range(dets.shape[0]) if not d in [m[0] for m in matched_indices]]\n",
        "            unmatched_trackers = [t for t in range(trks.shape[0]) if not t in [m[1] for m in matched_indices]]\n",
        "\n",
        "            #update matched trackers with assigned detections\n",
        "            for m in matched_indices:\n",
        "                self.trackers[m[1]].update(dets[m[0], :4])\n",
        "        else: #no trackers or no detections\n",
        "            unmatched_detections = list(range(dets.shape[0]))\n",
        "            unmatched_trackers = [] # If trks.size was 0\n",
        "\n",
        "        #create and initialise new trackers for unmatched detections\n",
        "        for i in unmatched_detections:\n",
        "            trk = KalmanBoxTracker(dets[i,:4])\n",
        "            self.trackers.append(trk)\n",
        "        i = len(self.trackers)\n",
        "        for trk in reversed(self.trackers):\n",
        "            d = trk.get_state()[0]\n",
        "            #only output tracks that have met min_hits and are not too old\n",
        "            if (trk.time_since_update < self.max_age) and (trk.hits >= self.min_hits or self.frame_count <= self.min_hits):\n",
        "                ret.append(np.concatenate((d,[trk.id+1])).reshape(1,-1)) #id+1 as MOT benchmark requires positive\n",
        "            i -= 1\n",
        "            #remove dead tracklet\n",
        "            if(trk.time_since_update > self.max_age):\n",
        "                self.trackers.pop(i)\n",
        "        if(len(ret)>0):\n",
        "            return np.concatenate(ret)\n",
        "        return np.empty((0,5))\n",
        "\n",
        "print(\"SORT Tracker classes defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCDDOla-ycP-",
        "outputId": "2a425510-aaf2-43eb-da13-8d3e36121ece"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SORT Tracker classes defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#detection and tracking logic\n",
        "import cv2\n",
        "import torch #coz YOLOv8 uses PyTorch\n",
        "from ultralytics import YOLO\n",
        "import time\n",
        "import pandas as pd #for saving tracking data to CSV\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow #for displaying images in Colab\n",
        "\n",
        "#config\n",
        "VIDEO_NAME_Processed = \"video1\"  #video name\n",
        "\n",
        "FRAMES_SOURCE_DIR = os.path.join(EXTRACTED_FRAMES_INPUT_DIR, VIDEO_NAME_Processed)\n",
        "\n",
        "\n",
        "#YOLO_MODEL_NAME = 'yolov8s.pt' #tried this but it's giving many false positives and false negatives so we'll try larger model\n",
        "YOLO_MODEL_NAME = 'yolov8l.pt'\n",
        "#the model will be downloaded automatically if not found in MODEL_DIR or cache\n",
        "\n",
        "\"\"\"\n",
        "Classes to detect (COCO class names for vehicles)\n",
        "You can find all COCO class names here: https://docs.ultralytics.com/datasets/coco/#dataset-yaml\n",
        "Or check model.names after loading model\n",
        "Common vehicle classes: 2: 'car', 3: 'motorcycle', 5: 'bus', 7: 'truck'\n",
        "\"\"\"\n",
        "TARGET_CLASSES_INDICES = [2, 3, 5, 7] #indices for car, motorcycle, bus, truck\n",
        "\n",
        "CONFIDENCE_THRESHOLD = 0.65 #min detection confidence\n",
        "\n",
        "#SORT Parameters\n",
        "SORT_MAX_AGE = 30    #max frames to keep a track without new detections\n",
        "SORT_MIN_HITS = 5    #min number of detections to start a track\n",
        "SORT_IOU_THRESHOLD = 0.2 #IoU threshold for matching detections to tracks\n",
        "\n",
        "SAVE_VISUALIZED_FRAMES = True #set to True to save frames with bounding boxes\n",
        "OUTPUT_CSV_FILENAME = f\"{VIDEO_NAME_Processed}_tracked_vehicles.csv\"\n",
        "OUTPUT_CSV_PATH = os.path.join(TRACKING_OUTPUTS_DIR, OUTPUT_CSV_FILENAME)\n",
        "\n",
        "#output directory for visualized frames (if SAVE_VISUALIZED_FRAMES is True)\n",
        "VIDEO_VISUALIZED_OUTPUT_DIR = os.path.join(VISUALIZED_FRAMES_DIR, VIDEO_NAME_Processed)\n",
        "if SAVE_VISUALIZED_FRAMES:\n",
        "    os.makedirs(VIDEO_VISUALIZED_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "#load YOLOv8 Model\n",
        "try:\n",
        "    model_path = os.path.join(MODEL_DIR, YOLO_MODEL_NAME)\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"Model {YOLO_MODEL_NAME} not found in {MODEL_DIR}. YOLO will attempt to download it.\")\n",
        "        model_path = YOLO_MODEL_NAME #let ultralytics handle download\n",
        "\n",
        "    yolo_model = YOLO(model_path)\n",
        "    print(f\"YOLOv8 model '{YOLO_MODEL_NAME}' loaded successfully.\")\n",
        "    #you can print yolo_model.names to see all class names it can detect\n",
        "    #print(\"Available classes:\", yolo_model.names)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading YOLOv8 model: {e}\")\n",
        "    #terminate or handle error appropriately\n",
        "    raise SystemExit(\"YOLO Model loading failed.\")\n",
        "\n",
        "\n",
        "#initialize SORT tracker\n",
        "mot_tracker = Sort(max_age=SORT_MAX_AGE,\n",
        "                   min_hits=SORT_MIN_HITS,\n",
        "                   iou_threshold=SORT_IOU_THRESHOLD)\n",
        "print(\"SORT tracker initialized.\")\n",
        "\n",
        "#process frames\n",
        "if not os.path.exists(FRAMES_SOURCE_DIR):\n",
        "    print(f\"ERROR: Extracted frames directory not found: {FRAMES_SOURCE_DIR}\")\n",
        "    print(f\"Please ensure '{VIDEO_NAME_Processed}' matches a subfolder in '{EXTRACTED_FRAMES_INPUT_DIR}'\")\n",
        "    print(f\"This subfolder should have been created by Notebook 1.\")\n",
        "\n",
        "else:\n",
        "    frame_files = sorted([f for f in os.listdir(FRAMES_SOURCE_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "    if not frame_files:\n",
        "        print(f\"No image frames found in {FRAMES_SOURCE_DIR}. Check the directory and file extensions.\")\n",
        "    else:\n",
        "        print(f\"Found {len(frame_files)} frames to process in {FRAMES_SOURCE_DIR}.\")\n",
        "\n",
        "        all_tracking_data = [] #to store data for CSV\n",
        "\n",
        "        for frame_idx, frame_filename in enumerate(frame_files):\n",
        "            frame_path = os.path.join(FRAMES_SOURCE_DIR, frame_filename)\n",
        "            try:\n",
        "                frame = cv2.imread(frame_path)\n",
        "                if frame is None:\n",
        "                    print(f\"Warning: Could not read frame {frame_filename}. Skipping.\")\n",
        "                    continue\n",
        "\n",
        "                start_time = time.time()\n",
        "\n",
        "                #perform detection\n",
        "                results = yolo_model.predict(source=frame, verbose=False) #verbose=False to reduce console output\n",
        "                detections = [] #list to store [x1, y1, x2, y2, score]\n",
        "\n",
        "                for res in results: #iterate through results for the single image\n",
        "                    boxes = res.boxes.cpu().numpy() #get boxes on CPU in numpy format\n",
        "                    for box in boxes: #iterate through detected boxes\n",
        "                        class_id = int(box.cls[0])\n",
        "                        confidence = box.conf[0]\n",
        "\n",
        "                        if class_id in TARGET_CLASSES_INDICES and confidence >= CONFIDENCE_THRESHOLD:\n",
        "                            x1, y1, x2, y2 = box.xyxy[0].astype(int) #bounding box coordinates\n",
        "                            detections.append([x1, y1, x2, y2, confidence])\n",
        "\n",
        "                detections_np = np.array(detections) if detections else np.empty((0, 5))\n",
        "\n",
        "                #update SORT tracker\n",
        "                #the dets format for SORT is [[x1,y1,x2,y2,score],...]\n",
        "                tracked_objects = mot_tracker.update(detections_np)\n",
        "                #tracked_objects format: [[x1,y1,x2,y2,track_id],...]\n",
        "\n",
        "                end_time = time.time()\n",
        "                processing_time = end_time - start_time\n",
        "\n",
        "                #store tracking data and draw on frame\n",
        "                frame_number = int(frame_filename.split('_f')[-1].split('_orig')[0]) if '_f' in frame_filename else frame_idx\n",
        "\n",
        "                for trk in tracked_objects:\n",
        "                    x1_trk, y1_trk, x2_trk, y2_trk, track_id = trk.astype(int)\n",
        "                    all_tracking_data.append({\n",
        "                        'frame_id': frame_number, #or frame_idx\n",
        "                        'track_id': track_id,\n",
        "                        'x1': x1_trk,\n",
        "                        'y1': y1_trk,\n",
        "                        'x2': x2_trk,\n",
        "                        'y2': y2_trk,\n",
        "                    })\n",
        "                    '''You could try to find the original detection score if needed, but SORT output doesn't directly carry it over for the track.\n",
        "                       We can infer the class based on what we fed to YOLO if all are same, or do a more complex association if YOLO detects multiple classes we track.\n",
        "                       For now, we assume all tracked objects are from TARGET_CLASSES_INDICES '''\n",
        "\n",
        "                    if SAVE_VISUALIZED_FRAMES:\n",
        "                        #draw bounding box\n",
        "                        cv2.rectangle(frame, (x1_trk, y1_trk), (x2_trk, y2_trk), (0, 255, 0), 2)\n",
        "                        #put track ID\n",
        "                        cv2.putText(frame, f\"ID: {track_id}\", (x1_trk, y1_trk - 10),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "                if SAVE_VISUALIZED_FRAMES:\n",
        "                    cv2.putText(frame, f\"Frame: {frame_number}\", (10, 30),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "                    cv2.putText(frame, f\"Time: {processing_time:.3f}s\", (10, 70),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "                    output_frame_path = os.path.join(VIDEO_VISUALIZED_OUTPUT_DIR, frame_filename)\n",
        "                    cv2.imwrite(output_frame_path, frame)\n",
        "\n",
        "                # Optional: Display every Nth frame in Colab (can be slow)\n",
        "                # if frame_idx % 20 == 0:\n",
        "                #     print(f\"Displaying frame {frame_number} (original filename: {frame_filename})\")\n",
        "                #     # Convert BGR (OpenCV) to RGB (Matplotlib) for display\n",
        "                #     # display_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                #     # plt.figure(figsize=(10,8))\n",
        "                #     # plt.imshow(display_frame)\n",
        "                #     # plt.title(f\"Tracked Frame: {frame_filename}\")\n",
        "                #     # plt.axis('off')\n",
        "                #     # plt.show()\n",
        "                #     cv2_imshow(frame) # Simpler display in Colab\n",
        "\n",
        "                if (frame_idx + 1) % 50 == 0: #print progress every 50 frames\n",
        "                    print(f\"Processed {frame_idx + 1}/{len(frame_files)} frames. Last frame: {frame_filename}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing frame {frame_filename}: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                continue # Skip to next frame\n",
        "\n",
        "        #save all tracking data to CSV\n",
        "        if all_tracking_data:\n",
        "            df_tracking = pd.DataFrame(all_tracking_data)\n",
        "            df_tracking.to_csv(OUTPUT_CSV_PATH, index=False)\n",
        "            print(f\"\\nTracking data saved to: {OUTPUT_CSV_PATH}\")\n",
        "            print(f\"CSV Head:\\n{df_tracking.head()}\")\n",
        "        else:\n",
        "            print(\"\\nNo tracking data was generated.\")\n",
        "\n",
        "        print(\"\\nDetection and tracking complete.\")\n",
        "        if SAVE_VISUALIZED_FRAMES:\n",
        "            print(f\"Visualized frames saved in: {VIDEO_VISUALIZED_OUTPUT_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqHczBaP1Fbm",
        "outputId": "e03e372d-2797-4793-d8c8-7118de24a2f0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model yolov8l.pt not found in /content/drive/My Drive/car-behaviour-project/models/yolov8. YOLO will attempt to download it.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l.pt to 'yolov8l.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83.7M/83.7M [00:00<00:00, 228MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8 model 'yolov8l.pt' loaded successfully.\n",
            "SORT tracker initialized.\n",
            "Found 466 frames to process in /content/drive/My Drive/car-behaviour-project/data/extracted_frames/video1.\n",
            "Processed 50/466 frames. Last frame: video1_f00049_orig000147.png\n",
            "Processed 100/466 frames. Last frame: video1_f00099_orig000297.png\n",
            "Processed 150/466 frames. Last frame: video1_f00149_orig000447.png\n",
            "Processed 200/466 frames. Last frame: video1_f00199_orig000597.png\n",
            "Processed 250/466 frames. Last frame: video1_f00249_orig000747.png\n",
            "Processed 300/466 frames. Last frame: video1_f00299_orig000897.png\n",
            "Processed 350/466 frames. Last frame: video1_f00349_orig001047.png\n",
            "Processed 400/466 frames. Last frame: video1_f00399_orig001197.png\n",
            "Processed 450/466 frames. Last frame: video1_f00449_orig001347.png\n",
            "\n",
            "Tracking data saved to: /content/drive/My Drive/car-behaviour-project/data/tracking_outputs/video1_tracked_vehicles.csv\n",
            "CSV Head:\n",
            "   frame_id  track_id    x1    y1    x2    y2\n",
            "0         0         5   240   873   348   964\n",
            "1         0         4   733   866   844   943\n",
            "2         0         3   476  1324   758  1439\n",
            "3         0         2   922  1277  1233  1431\n",
            "4         0         1  1238  1247  1620  1395\n",
            "\n",
            "Detection and tracking complete.\n",
            "Visualized frames saved in: /content/drive/My Drive/car-behaviour-project/data/visualized_tracked_frames/video1\n"
          ]
        }
      ]
    }
  ]
}