# Behavior Detection at Pedestrian Crossings

A computer vision project to analyze driver behavior at zebra crossings using YOLOv8 and object tracking. This project detects vehicles, estimates their speed, and classifies their behavior into categories.

## Project Objectives

1. Detect and track vehicles from surveillance footage.
2. Estimate their speed using frame-by-frame object tracking.
3. Classify vehicle behavior based on three positive traits:
  - **B1**: Reducing speed as the car is approaching the pedestrian crossing.
  - **B2**: Stopping at the crossing when a red light is shown, or pedestrians are crossing.
  - **B3**: Stop behind the crossing line.

> This project is inspired by work conducted with the Kuyesera AI Lab at MUBAS, under the leadership of Principal Investigator Dr. Amelia Taylor and guidance of Prof G.R. Sinha.

> NOTE that data is not included in this repo as it exceeds git's file size and data limit. **Refer to the drive link below**

> Here's the link to drive folder containing all the raw and extracted data and the notebooks: https://drive.google.com/drive/folders/19tOeHkWPvRAXDDVmK2OMGSgiqTCMGbf3?usp=drive_link

## Overview of Pipeline Implemented
##### 1. Video loading & frame extraction
* Used OpenCV to load video and sample frames at fixed FPS_EXTRACT (extract 10 frames per sec of video footage)
* Stored extracted frames according to time series
  
##### 2. Object Detection (YOLOv8)
* Used Ultralytics YOLOv8 (pretrained yolov8l) as baseline
* Target Classes: Vehicle-related COCO classes — cars, motorcycles, buses, and trucks ([2, 3, 5, 7])
Thresholds:
* Confidence ≥ 0.65 to reduce false positives
* Each detection returns bounding box coordinates (x1, y1, x2, y2) and class confidence
  
##### 3 Multi-Object Tracking with SORT
* Tracker Used: A Python implementation of Simple Online and Realtime Tracking (SORT) based on a Kalman Filter and Hungarian (linear sum) assignment algorithm.
* Core Steps:
    * Prediction - Kalman Filter predicts object positions in the next frame.
    * Association - Matches detections to existing tracks using Intersection over Union (IoU ≥ 0.3).
    * Update - Updates matched tracks with new detections.
    * Initialization - Creates new tracks for unmatched detections.
* Parameters:
    * max_age = 30: Maximum frames to retain a track without new detections.
    * min_hits = 5: Minimum detections before confirming a valid track.
    * iou_threshold = 0.2: IoU threshold for detection-track assignment.
*Each vehicle receives a unique track_id maintained across frames, enabling trajectory reconstruction

##### 4. Speed Estimation
* Load per-frame bounding boxes and track IDs generated by the SORT tracker; group detections by track_id to maintain temporal continuity
* For each tracked vehicle, compute centroid displacement between consecutive frames and convert pixel distance to meters using a calibrated PIXELS_PER_METER ratio and video frame rate (TIME_INTERVAL_SECONDS)
* Merge calculated speeds back into the tracking data, producing a unified CSV file with frame ID, object ID, centroid coordinates, and derived motion metrics

##### 5. Behaviour Analysis Configuration
* Region of Interest (ROI) Definition - Predefined rectangular zones (Approach Zones, Stop Lines, and Crossing Zone) are manually annotated in pixel coordinates to localize vehicle activity relative to the pedestrian crossing
* Lane-Specific Logic - Each lane (closer_lane, far_lane) is assigned movement direction metadata (left/right) for accurate interpretation of entry and exit events within ROIs
* Configurable parameters determine compliance patterns. For eg:
    * minimum speed reduction (MIN_SPEED_REDUCTION_KMH)
    * stopping criteria (STOPPING_SPEED_THRESHOLD_KMH)
    * required frame duration thresholds (MIN_FRAMES_IN_APPROACH_FOR_B1, MIN_STOP_DURATION_FRAMES)
* The pipeline merges computed speed data with behavioural classification results; saving per-frame and per-vehicle behavioural outcomes (*_behaviour_classified.csv)

###### 6. Planned (Future Scope)
* Automated Behavioural Tagging: Use the defined ROIs and thresholds to classify vehicle behaviour into categories such as Approach, Stop, Cross, and Violation
* Context-Aware Decisions: Integrate manual annotations (e.g., pedestrian presence, red-light status) with motion data to improve classification accuracy
* Visual Feedback Layer: Future versions will overlay behaviour tags and violation highlights directly on processed video frames for easier validation and visualization.


## Drive Folder Structure
```bash
car-behaviour-project/
├── data/                         
│ ├── raw_videos/                       #original surveillance footages
│ ├── extracted_frames/                 #frames extracted at 10 FPS
│ ├── visualized_tracked_frames/        #frames with objects (vehicles) detected and tracked with their ID (visuualized as bounding boxes)
│ ├── tracking_outputs/                 #csv file with tracker outputs (with IDs)
│ ├── speed_estimation_outputs/         #csv file containing speed estimations for different vehicles (tracked by ID)
│ ├── behaviour_classification_outputs/
│ └── behavior_annotations/             #behavior labels
│
├── notebooks/                          #notebooks are just to test code in sections (on colab) before adding it  to src
│ ├── 1_extract_frames.ipynb           
│ ├── 2_detect_and_track.ipynb           
│ ├── 3_speed_estimation.ipynb
│ └── 4_behaviour_classification.ipynb
│
└── models
  ├── yolov8/
```

## Project Structure
```bash
car-behaviour-detection/
│
├── models
│ ├── yolov8/
│
├── src/                          #source code for our project
│ ├── extract_frames.py           #extracts frames from video
│ ├── detect_yolo.py              #YOLOv8 detection logic
│ ├── track_sort.py               #vehicle tracking using SORT
│ ├── calculate_speed.py          #speed estimation logic
│ └── classify_behavior.py        #rule-based behavior classification
│
├── main.py                       #main orchestration pipeline
├── pyproject.toml                #Poetry config
├── poetry.lock                   #locked dependency versions
└── README.md                     #you're here!
```

## Tech Stack

- **YOLOv8** – Object detection (via [Ultralytics](https://github.com/ultralytics/ultralytics))
- **OpenCV** – Frame extraction & visualization
- **SORT** – Vehicle tracking with consistent IDs
- **Poetry** – Python dependency & virtual environment management
  
## Setup Instructions (with Poetry)

### 1. Clone the repo

```bash
git clone https://github.com/your-username/behavior-detection-project.git
cd behavior-detection-project
```

### 2. Install Poetry (if not done so already)
Follow official instructions: https://python-poetry.org/docs/#installation
or
```bash
curl -sSL https://install.python-poetry.org | python3 -
```
> After installing poetry , add it to PATH and restart your terminal

### 3. Install dependencies
```bash
poetry install
```
### 4. Activate virtual environment
```bash
poetry shell
```
### 5. Run the full pipeline
